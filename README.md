# üöÄ D√©tection d'√âmotions en Temps R√©el via Webcam

[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)

Ce projet a pour objectif de d√©tecter les √©motions humaines en temps r√©el √† partir du flux vid√©o d'une webcam. Il utilise des techniques de vision par ordinateur pour extraire les points de rep√®re du visage (facial landmarks) et des mod√®les de Machine Learning pour classifier l'√©motion correspondante.


## üìã Table des Mati√®res
1. [Fonctionnalit√©s Cl√©s](#-fonctionnalit√©s-cl√©s)
2. [Technologies Utilis√©es](#-technologies-utilis√©es)
3. [Pr√©requis](#-pr√©requis)
4. [Installation](#-installation)
5. [Utilisation](#-utilisation)
6. [Comment √ßa fonctionne ?](#-comment-√ßa-fonctionne-)
7. [Structure du Projet](#-structure-du-projet)
8. [Contribuer](#-contribuer)
9. [Licence](#-licence)

## ‚ú® Fonctionnalit√©s Cl√©s
- **D√©tection de visage en temps r√©el** : Localise le visage principal dans le flux vid√©o.
- **Extraction de 68 points de rep√®re faciaux** : Cartographie les traits du visage (yeux, bouche, nez...).
- **Classification d'√©motions** : Utilise des mod√®les pr√©-entra√Æn√©s pour pr√©dire l'√©motion.
- **Deux mod√®les au choix** :
  - **Support Vector Machine (SVM)** : Un classifieur robuste et efficace.
  - **Random Forest** : Un mod√®le d'ensemble performant.
- **Affichage en direct** : L'√©motion d√©tect√©e est affich√©e directement sur le flux vid√©o.

## üõ†Ô∏è Technologies Utilis√©es
- **Python 3.8+**
- **OpenCV** : Pour la capture et le traitement vid√©o en temps r√©el.
- **Dlib** : Pour la d√©tection de visages et l'extraction des points de rep√®re faciaux.
- **Scikit-learn** : Pour l'impl√©mentation des mod√®les SVM et Random Forest.
- **Joblib** : Pour la sauvegarde et le chargement des mod√®les entra√Æn√©s.
- **Numpy** : Pour les manipulations num√©riques.
- **Jupyter Notebook** : Pour l'exp√©rimentation et l'entra√Ænement des mod√®les.

## üõë Pr√©requis
Avant de commencer, vous aurez besoin de t√©l√©charger le mod√®le pr√©-entra√Æn√© de Dlib pour la d√©tection des points de rep√®re faciaux :
- **[shape_predictor_68_face_landmarks.dat](http.dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2)**

T√©l√©chargez-le, d√©compressez-le et placez le fichier `shape_predictor_68_face_landmarks.dat` √† la racine de votre projet.

## üîß Installation

Suivez ces √©tapes pour mettre en place l'environnement de d√©veloppement.

**1. Clonez le d√©p√¥t :**
```bash
git clone https://github.com/<VOTRE-USERNAME>/emotion-detection-webcam.git
cd emotion-detection-webcam
```

**2. Cr√©ez un environnement virtuel (recommand√©) :**
```bash
python -m venv venv
source venv/bin/activate  # Sur Windows: venv\Scripts\activate
```

**3. Installez les d√©pendances :**
Cr√©ez un fichier `requirements.txt` avec le contenu suivant :
```txt
opencv-python
dlib
scikit-learn==1.3.0  # Sp√©cifier une version peut √©viter des conflits
numpy
```
Puis installez-le :
```bash
pip install -r requirements.txt
```

**4. Pr√©parez le jeu de donn√©es :**
Ce projet utilise un jeu de donn√©es qui n'est pas inclus dans le d√©p√¥t. **Veuillez ajouter ici les instructions pour que l'utilisateur t√©l√©charge et d√©compresse `archive_4.zip` au bon endroit.**

**5. Entra√Ænez les mod√®les :**
Les mod√®les `.joblib` sont ignor√©s par Git. Vous devez les g√©n√©rer en ex√©cutant les notebooks Jupyter. Lancez Jupyter :
```bash
jupyter notebook
```
Ouvrez et ex√©cutez les cellules des deux notebooks suivants pour entra√Æner les mod√®les et sauvegarder les fichiers `.joblib` dans les dossiers `joblib SVM/` et `joblib RandomForest/` :
- `SVM_WEBCAM_FINAL.ipynb`
- `AMELIORATION_MODELE_WEBCAM.ipynb`

## ‚ñ∂Ô∏è Utilisation

Une fois l'installation termin√©e, vous pouvez lancer la d√©tection d'√©motions. Assurez-vous que votre webcam est connect√©e et fonctionnelle.

**Pour utiliser le mod√®le SVM :**
```bash
python webcamwithmodelsvm.py
```

**Pour utiliser le mod√®le Random Forest :**
```bash
python webcamwithmodelrandomforest.py
```
Appuyez sur la touche **'q'** pour quitter l'application.

## üß† Comment √ßa fonctionne ?
Le pipeline de traitement est le suivant :
1.  **Capture Vid√©o** : Une image est captur√©e depuis la webcam.
2.  **D√©tection de Visage** : La biblioth√®que Dlib d√©tecte la position du visage dans l'image.
3.  **Extraction des Points de Rep√®re** : Le mod√®le `shape_predictor_68_face_landmarks.dat` est utilis√© pour extraire les 68 points cl√©s du visage.
4.  **Pr√©traitement** : Les coordonn√©es des points sont normalis√©es et une Analyse en Composantes Principales (ACP) est appliqu√©e pour r√©duire la dimensionnalit√© et extraire les caract√©ristiques les plus pertinentes.
5.  **Pr√©diction** : Le vecteur de caract√©ristiques est pass√© au mod√®le de Machine Learning charg√© (SVM ou Random Forest) qui pr√©dit l'√©motion.
6.  **Affichage** : Un rectangle est dessin√© autour du visage et l'√©motion pr√©dite est affich√©e en haut de celui-ci.

## üìÇ Structure du Projet
```
.
‚îú‚îÄ‚îÄ .gitignore                    # Fichiers √† ignorer par Git
‚îú‚îÄ‚îÄ AMELIORATION_MODELE_WEBCAM.ipynb # Notebook pour l'entra√Ænement du mod√®le Random Forest
‚îú‚îÄ‚îÄ SVM_WEBCAM_FINAL.ipynb        # Notebook pour l'entra√Ænement du mod√®le SVM
‚îú‚îÄ‚îÄ webcamwithmodelrandomforest.py # Script principal (utilise le mod√®le Random Forest)
‚îú‚îÄ‚îÄ webcamwithmodelsvm.py         # Script principal (utilise le mod√®le SVM)
‚îú‚îÄ‚îÄ requirements.txt              # Liste des d√©pendances Python
‚îú‚îÄ‚îÄ README.md                     # Ce fichier
‚îî‚îÄ‚îÄ shape_predictor_68_face_landmarks.dat # (Pr√©requis) Mod√®le Dlib
```

## ü§ù Contribuer
Les contributions sont les bienvenues ! Si vous avez des id√©es pour am√©liorer ce projet, n'h√©sitez pas √† forker le d√©p√¥t et √† cr√©er une Pull Request.
1. Forkez le projet.
2. Cr√©ez votre branche de fonctionnalit√© (`git checkout -b feature/NouvelleFonctionnalite`).
3. Commitez vos changements (`git commit -m 'feat: Ajout d'une nouvelle fonctionnalit√©'`).
4. Pushez vers la branche (`git push origin feature/NouvelleFonctionnalite`).
5. Ouvrez une Pull Request.
